{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from [Pytorch tutorial for Deep Learning researchers](https://github.com/yunjey/pytorch-tutorial) (Yunvey Choi, 2018).\n",
    "\n",
    "Used as part of Deep Learning, Gilles Louppe, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic autograd example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors.\n",
    "x = Variable(torch.Tensor([1]), requires_grad=True)\n",
    "w = Variable(torch.Tensor([2]), requires_grad=True)\n",
    "b = Variable(torch.Tensor([3]), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3\n",
    "\n",
    "# Compute gradients.\n",
    "y.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print(x.grad)    # x.grad = 2 \n",
    "print(w.grad)    # w.grad = 1 \n",
    "print(b.grad)    # b.grad = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic autograd example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      " 0.0617 -0.4733  0.3023\n",
      "-0.4100  0.0271 -0.2699\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "b:  Parameter containing:\n",
      "-0.5201\n",
      "-0.0465\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create tensors.\n",
    "x = Variable(torch.randn(5, 3))\n",
    "y = Variable(torch.randn(5, 2))\n",
    "\n",
    "# Build a linear layer.\n",
    "linear = nn.Linear(3, 2)\n",
    "print('w: ', linear.weight)\n",
    "print('b: ', linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.4236 -0.0147\n",
      "-1.2864  0.3496\n",
      "-0.1673 -0.0767\n",
      "-0.1987 -0.1804\n",
      "-0.5573  0.8858\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Forward propagation.\n",
    "pred = linear(x)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  1.92258620262146\n"
     ]
    }
   ],
   "source": [
    "# Build Loss and Optimizer.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
    "\n",
    "# Compute loss.\n",
    "loss = criterion(pred, y)\n",
    "print('loss: ', loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dw:  Variable containing:\n",
      " 1.0218 -0.6281 -0.0250\n",
      "-0.5562 -0.0586 -0.5835\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "dL/db:  Variable containing:\n",
      "-1.3196\n",
      " 0.3208\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Backpropagation.\n",
    "loss.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print ('dL/dw: ', linear.weight.grad) \n",
    "print ('dL/db: ', linear.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 1 step optimization:  1.8834739923477173\n"
     ]
    }
   ],
   "source": [
    "# 1-step Optimization (gradient descent).\n",
    "optimizer.step()\n",
    "\n",
    "# You can also do optimization at the low level as shown below.\n",
    "# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
    "# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n",
    "\n",
    "# Print out the loss after optimization.\n",
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('loss after 1 step optimization: ', loss.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2], [3,4]])\n",
    "b = torch.from_numpy(a)      # convert numpy array to torch tensor\n",
    "c = b.numpy()                # convert torch tensor to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download and construct dataset.\n",
    "train_dataset = dsets.CIFAR10(root='./data/',\n",
    "                              train=True, \n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Select one data pair (read data from disk).\n",
    "image, label = train_dataset[7]\n",
    "print(image.size())\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f36e50ada58>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (this provides queue and thread in a very simple way).\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "# When iteration starts, queue and thread start to load dataset from files.\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# Mini-batch images and labels.\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "# Actual usage of data loader is as below.\n",
    "for images, labels in train_loader:\n",
    "    # Your training code will be written here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input pipeline for custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should build custom dataset as below.\n",
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self):\n",
    "        # TODO\n",
    "        # 1. Initialize file path or list of file names. \n",
    "        pass\n",
    "    def __getitem__(self, index):\n",
    "        # TODO\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return 0 \n",
    "\n",
    "# Then, you can just use prebuilt torch's data loader. \n",
    "custom_dataset = CustomDataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load pretrained resnet.\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# If you want to finetune only top layer of the model.\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# Replace top layer for finetuning.\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11227812\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.4477  0.1277  0.4070  ...  -0.9360  0.6794  0.1676\n",
      " 0.0243  0.1258  0.3957  ...  -0.2681  0.3237 -0.0667\n",
      "-0.1448  0.7133  0.4125  ...  -0.9420  0.0956 -0.1264\n",
      "          ...             â‹±             ...          \n",
      "-0.0484  0.3275 -0.1714  ...  -0.5008  0.7650  0.1089\n",
      "-0.1188  0.4415  0.8941  ...  -0.4662  0.8276  0.2353\n",
      "-0.7835  0.4349  0.3300  ...  -0.8063  1.2214  0.2567\n",
      "[torch.FloatTensor of size 10x100]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For test.\n",
    "images = Variable(torch.randn(10, 3, 224, 224))\n",
    "outputs = resnet(images)\n",
    "print(outputs)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the entire model.\n",
    "torch.save(resnet, 'model.pkl')\n",
    "model = torch.load('model.pkl')\n",
    "\n",
    "# Save and load only the model parameters(recommended).\n",
    "torch.save(resnet.state_dict(), 'params.pkl')\n",
    "resnet.load_state_dict(torch.load('params.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
