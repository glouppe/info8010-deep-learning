class: middle, center, title-slide

# Deep Learning

Lecture 10: Attention and transformer networks

<br><br>
Prof. Gilles Louppe<br>
[g.louppe@uliege.be](g.louppe@uliege.be)

???

R: https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html <-- very good!

R: https://jalammar.github.io/illustrated-gpt2/
R: https://twitter.com/Ben_Hoov/status/1183823783754371076?s=03  --> BERT visualization
http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture14-transformers.pdf

R: 1912.01412

R: google meena

https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/

R: set transformer https://arxiv.org/abs/1810.00825

---

class: middle

## Image captioning

.center[
.width-100[![](figures/lec6/sat.png)]
]

.footnote[Credits: Kelvin Xu et al, [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](https://arxiv.org/abs/1502.03044), 2015.]

---

class: middle

.center[
.width-100[![](figures/lec6/sat-demo.jpg)]
]

.footnote[Credits: Kelvin Xu et al, [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](https://arxiv.org/abs/1502.03044), 2015.]